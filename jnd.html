<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html>

<head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">



<title>ShenXuelin</title>

  <link rel="stylesheet" href="./OL_files/bootstrap.min.css">
  <link href="./OL_files/css" rel="stylesheet" type="text/css">
  <link href="./OL_files/style.css" rel="stylesheet" type="text/css">
  <script type="text/javascript" async="" src="./OL_files/ga.js.download"></script>
  <script type="text/javascript" src="./OL_files/hidebib.js.download"></script>

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-133713714-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-133713714-1');
</script>

</head>

<body>


<!-- Start main content -->

  <div class="container">
    <table width="900" border="0" align="center" cellpadding="20">
      </table><table width="90%" align="center" border="0" cellpadding="10">
        <tbody><tr>
          <td width="70%" valign="top">
            <p align="center">&nbsp;</p>

            <p align="center"><font size="6px">A JND DATASET BASED ON VVC COMPRESSED IMAGES
            </font><br></p>
            <p>XUELIN SHEN<sup>1</sup>, ZHANGKAI NI<sup>1</sup>,WENHAN YANG<sup>1</sup>, SHIQI WANG<sup>1</sup>, XINFENG ZHANG<sup>2</sup>, SAM KWONG<sup>1</sup>  </p>
            <p style="MARGIN-TOP: 10pt; margin-bottom: 0pt;" align="center"><sup>1</sup>Department of Computer Science, City University of Hong Kong, Kowloon Tong, Hong Kong</p>
            <p style="MARGIN-TOP: 0pt; margin-bottom: 0pt;" align="center"><sup>2</sup>School of Computer Science and Technology, University of Chinese Academy of Sciences, Beijing, China</p>

        </tr>
      </tbody></table>
  </div>

  <div class="container">
    <h2>Abstract</h2><div class="bastract">
      <p>In this paper, we establish a just noticeable distortion (JND) dataset based on the next generation video coding standard Versatile Video Coding (VVC). The dataset consists of 202 images which cover a wide range of content with resolution 1920×1080. Each image is encoded by VTM 5.0 intra coding with the quantization parameter (QP) ranging from 13 to 51. The details regarding dataset construction, subjective testing and data post-processing are described in this paper. Finally, the significance of the dataset towards future video coding re- search is envisioned. All source images as well as the testing data have been made available to the public.</p>
  </div>


    <h2>Database</h2><div class="database">
    <table>
        <tbody>
            <tr>
                <td width="1000">
                    <div class="example">
                        <img src="./OL_files/database.JPG" alt="Dummy Image" width="900" />
                    </div>
                </td>
            </tr>
        </tbody>
    </table>
    <br />



    <!--
    <head>
        <meta charset="utf-8">
        <title>guess</title>
    </head>
        <body>
            <a href="readme.txt">Readme and download link</a>
        </body>
     -->
    <!--
        </div>
        Readme:If you are using this dataset in your research work, please kindly refer to the following paper:
        [1] Xuelin Shen, Zhangkai Ni, Wenhan Yang, Xinfeng Zhang, Shiqi Wang, and Sam Kwong. A JND DATASET BASED ON VVC COMPRESSED IMAGES, IEEE International Conference on Multimedia and Expo (ICME) 2019.

        Explain:The VVC based JND dataset contains 202 source images with resolution 1920*1080 and 39 compressed images for each source image with quantization parameter(QP) set ranging from 1 to 100 through VTM5.0 intra. The source/distorted images are classified into 4 sessions in the folder session#_Ori/session#_Dis, respectively.
        Each source image and its distorted images (a session) were viewed by 20 volunteers, their JND samples for the 4 sessions were recorded under ''f_session#.mat'' file.  Each file contains a 50*20 or 51*20 matrix, each row of the matrix represent the  raw samples from certain subject for the whole session
    </div>
    -->
    <!--
      <div class="container">
        <h2>News</h2><div class="news">
            <ul>
            <li><span> April 25: I was invited as a speaker at the <a href=https://dl4sci-school.lbl.gov/home>Deep Learning for Science Summer School</a> </span></li><p></p>
            <li><span> April 23: Our paper <a href=https://arxiv.org/pdf/1805.09622.pdf>SOSELETO: A Unified Approach to Transfer Learning and Training with Noisy Labels</a> just won <mark>Best paper award</mark> at ICLR workshop on <a href=https://lld-workshop.github.io/>Learning from Limited Labeled Data</a></span></li><p></p>
            <li><span> April 22: Check out our new paper on <a href=https://arxiv.org/pdf/1904.09664.pdf>Object detection in 3D point clouds</a> </span></li><p></p>
             <li><span> Our paper <a href=https://arxiv.org/pdf/1812.02415.pdf>"Self-supervised Learning of Dense Shape Correspondence"</a> was accepted as an <strong>oral presentation</strong> at CVPR 2019!
               </span></li><p></p>
             <li><span> We are organizing a <a href="https://sites.google.com/view/eccv2018fmapstutorial/home">tutorial</a> on "Functional Maps: A Flexible Representation for Learning and Computing Correspondence" at ECCV 2018 in Munich. See you there! <p></p>
             </span></li>
             <li><span> Our paper <a href="https://arxiv.org/pdf/1701.01687">"Class-Aware Fully-Convolutional Gaussian and Poisson Denoising"</a> has been accepted for publication at TIP.
                 </span></li>
          </ul>
          </div><table width="90%" border="0" align="center" cellpadding="20">
        </table>
      </div>
    -->
    <!--
    //  Talks
      <div class="container">
        <h2>Invited talks</h2><div class="news">
            <ul>
            <li><span> Deep Learning for “Exotic” Data Like 3D Meshes and Point-Clouds <br>
              <a href="https://www.meetup.com/San-Francisco-Machine-Learning-Meetup/events/257153311/">San Francisco Deep Learning Meetup</a> <br>
              <a href="https://drive.google.com/open?id=1XDV4fcLXcQP72JYNzRRX6zXbEZLwM8ay">slides / <a href="https://youtu.be/fY_BzTmU9io">video</a> </span></li><p></p>
            <li><span> Deep Hough Voting for 3D object detection in point clouds <br>
              Xerox PARC, NYU, Cornell-Tech <br>
              <a href="./OL_files/talks/deep_hough_voting.pdf">slides</a>
            <li><span> SOSELETO: A Unified Approach to Transfer Learning and Training with Noisy Labels <br>
              ICLR LLD workshop, New Orleans <br>
              <a href="./OL_files/talks/./OL_files/SOSELETO ICLR19_presentation.pdf">slides</a>
              <a href="https://slideslive.com/38915478/r01-the-2nd-learning-from-limited-labeled-data-lld-workshop-representation-learning-for-weak-supervision-and-beyond">talk (starts at 2:03, slide 303)</a>

            </ul>

          </div><table width="90%" border="0" align="center" cellpadding="20">
        </table>
      </div>
    -->
    <!--
    // Workshops / Tutorials
      <div class="container">
        <h2>Workshops / Tutorials</h2><div class="news">
            <ul>
            <li><span> <a href="=https://geometry.cs.ucl.ac.uk/creativeai_eg19/">Deep Learning for Computer Graphics and Geometry Processing</a> <br>
              With: <a href=http://www0.cs.ucl.ac.uk/staff/n.mitra/>Niloy J. Mitra</a>,
              <a href=http://www0.cs.ucl.ac.uk/staff/I.Kokkinos/>Iasonas Kokkinos</a>,
              <a href=https://geometry.stanford.edu/member/guibas/>Leonidas Guibas</a>,
              <a href=https://www.imperial.ac.uk/people/m.bronstein>Michael Bronstein</a>,
              <a href=https://sites.google.com/site/erodola/>Emanuele Rodolà</a>,
              <a href=https://www.ics.usi.ch/index.php/people-detail-page/268-federico-monti>Federico Monti</a> <br>
              Tutorial at Eurographics 2019
            <li><span><a href=https://sites.google.com/view/eccv2018fmapstutorial/home>Functional Maps: A Flexible Representation for Learning and Computing Correspondence</a> <br>
              With: Maks Ovsjanikov, Emanuele Rodolà, Leonidas Guibas <br>
              Tutorial at ECCV 2018
            <li><span><a href=https://www.eusipco2017.org/workshops/#collapse3>Deep Learning and Geometry</a>
              With: Ron Kimmel, Emanuele Rodolà, Michael Bronstein, Alex Bronstein <br>
              Workshop at EUSIPCO 2017
            </ul>
          </div><table width="90%" border="0" align="center" cellpadding="20">
        </table>
      </div>
      -->
    <br />

    <!--
      <div class="container">
        <h2> Publications </h2>
      // Auto publications reader
      <div id="read_pub_record">
        <div v-for="pub in data.publications" class="publication">

          <table width="900" align="center" border="0" cellpadding="0">
              <tbody><tr>
                <td width="25%" valign="top">
                  <img :src="pub.image" alt="game" width="150" height="120" style="border-style: none">
                </td>
                <td width="75%" valign="top">
                  <p><a :href="pub.paper">
                    <heading>{{ pub.name }}</heading></a><br>
                    <span v-html="pub.authors"></span><br>
                    <em>{{ pub.publication }}</em>
                    <span v-if="pub.misc">
                      <br><span v-html="pub.misc"></span><br>
                    </span>

                  </p>
                  <div class="paper" :id="pub.name">
                    <a :href="pub.paper">paper</a> /
                    <span v-if="pub.code">
                      <a :href="pub.code">code</a> /
                    </span>
                    <span v-if="pub.dataset">
                      <a :href="pub.dataset">dataset</a> /
                    </span>
                    <span v-if="pub.slides">
                      <a :href="pub.slides">slides</a> /
                    </span>
                    <span v-if="pub.poster">
                      <a :href="pub.poster">poster</a> /
                    </span>

                    <a shape="rect" :href="'javascript:togglebib(\'' + pub.name + '\')'" class="togglebib">bibtex</a>

                    <pre xml:space="preserve" style="display: none;">{{ pub.bibtex }}
                    </pre>
                  </div>
                </td>

              </tr></tbody></table>
              <hr>
        </div>
    -->

</div>



  <script
    src="https://cdnjs.cloudflare.com/ajax/libs/vue/2.1.6/vue.min.js">
  </script>

  <script src="./publications.js"></script>

  <script>
    new Vue({
      el: "#read_pub_record",
      data() {
        return {
          data: data,
        }
      }
    });
  </script>

  <!-- Publications.-->

  </div><br>



<script xml:space="preserve" language="JavaScript">
hideallbibs();
</script>




</body></html>
